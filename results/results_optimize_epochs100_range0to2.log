epoch,training loss,train accuracy,test loss,test accuracy
0,3.219758030695793,0.6061719059944153,5.250995635986328,0.6223214864730835
1,3.1282695562411575,0.6144076585769653,5.072033882141113,0.6202380657196045
2,3.021186883632953,0.6012105941772461,4.9945268630981445,0.6208333373069763
3,2.8788889340865307,0.6098266839981079,4.623837471008301,0.6116071939468384
4,2.831154215030181,0.6150195598602295,4.754167556762695,0.6386905312538147
5,2.650089829395979,0.6258351802825928,4.9586310386657715,0.6089286208152771
6,2.8188556723105602,0.6149203181266785,4.444825172424316,0.624404788017273
7,2.479911607045394,0.6264967322349548,4.240977764129639,0.6425595283508301
8,2.404836517113906,0.639032244682312,4.378840923309326,0.6455357074737549
9,2.2102469542087655,0.6377919316291809,4.262811183929443,0.6407737731933594
10,1.9599849505302234,0.6470860838890076,3.511594533920288,0.6529762744903564
11,1.8444512562874036,0.6435801386833191,2.7730817794799805,0.636904776096344
12,2.6266295512517295,0.6244625449180603,4.960673809051514,0.6375000476837158
13,2.370119434136611,0.6338889598846436,4.541146755218506,0.6425595283508301
14,1.885191104350946,0.6400079727172852,2.855950355529785,0.661309540271759
15,1.3628754615783691,0.6555864214897156,2.079021692276001,0.6616071462631226
16,1.0881697688347254,0.6665674448013306,1.8957993984222412,0.6860119104385376
17,0.9297426113715539,0.6832043528556824,2.600733757019043,0.6809524297714233
18,0.8905367056528727,0.6868261098861694,1.402579665184021,0.6755952835083008
19,0.9993990002534329,0.6751670837402344,1.1453218460083008,0.6747024059295654
20,0.7750588655471802,0.6871237754821777,1.219464898109436,0.6877976655960083
21,0.5648689705591935,0.7033969163894653,1.1392223834991455,0.7101191282272339
22,0.5645449199737647,0.7181154489517212,1.3828999996185303,0.6895833015441895
23,0.5688966367489252,0.7091023921966553,0.8309651613235474,0.718154788017273
24,0.4053507454884358,0.732271671295166,0.9903162717819214,0.7303571701049805
25,0.3678399056960375,0.7415989637374878,0.7643253207206726,0.7488095164299011
26,0.3228156960163361,0.7440961599349976,0.5506398677825928,0.7345237731933594
27,0.2538985636753914,0.7587815523147583,0.44817832112312317,0.7559523582458496
28,0.20325925946235657,0.7762287855148315,0.44331640005111694,0.7651786208152771
29,0.17583361745644838,0.7864987254142761,0.4105435311794281,0.7693452835083008
30,0.16412922338797495,0.7905504107475281,0.4438573122024536,0.766964316368103
31,0.1498176722954481,0.7981411814689636,0.4229549169540405,0.7705358266830444
32,0.14626384067993897,0.8020110130310059,0.3814961910247803,0.7785714864730835
33,0.12088548573545921,0.8099986910820007,0.3791511356830597,0.7842262983322144
34,0.10795035805457677,0.8191937208175659,0.3315557539463043,0.78125
35,0.09761030742755303,0.8241549730300903,0.3358054757118225,0.7952381372451782
36,0.08574454811138985,0.8315472602844238,0.3204684853553772,0.798214316368103
37,0.0798547516266505,0.8363763093948364,0.345477432012558,0.7907738089561462
38,0.07170805354148914,0.842677116394043,0.32165876030921936,0.8014881014823914
39,0.06654203071808204,0.8471423387527466,0.2822839617729187,0.8041666746139526
40,0.06168939841863436,0.848581075668335,0.285000205039978,0.8032738566398621
41,0.05488718033601076,0.8583217859268188,0.28074753284454346,0.8160714507102966
42,0.052081596392851606,0.8617781400680542,0.2553103566169739,0.8095237612724304
43,0.05795471446636396,0.8614143133163452,0.34553012251853943,0.8017857074737549
44,0.07146650543197608,0.8453562259674072,0.2721598744392395,0.8092262148857117
45,0.06063259727297685,0.856238067150116,0.2892320454120636,0.8142857551574707
46,0.05791007851560911,0.8565853834152222,0.26254957914352417,0.8205357789993286
47,0.058238923931733154,0.861066997051239,0.3103870749473572,0.8154761791229248
48,0.062141539385685556,0.8597275018692017,0.24458816647529602,0.8166666030883789
49,0.054084305388805196,0.8634650111198425,0.25938019156455994,0.8291666507720947
50,0.04471927002454416,0.8744791746139526,0.298514187335968,0.8360118865966797
51,0.03954975722500911,0.8819706439971924,0.21434429287910461,0.8333333730697632
52,0.037257575358335786,0.8873288631439209,0.23177362978458405,0.8392857313156128
53,0.03026712270310292,0.8969206809997559,0.23237647116184235,0.8419643640518188
54,0.030110784782431066,0.8989548087120056,0.24583011865615845,0.8306547999382019
55,0.035051872714971885,0.8914632797241211,0.21736937761306763,0.8342262506484985
56,0.03099070207621807,0.892802894115448,0.2371627688407898,0.841369092464447
57,0.03585213040694212,0.8871800303459167,0.2523905336856842,0.8377976417541504
58,0.029744202891985577,0.8968380689620972,0.2425369769334793,0.8517857789993286
59,0.02675892947575985,0.9071409702301025,0.26122376322746277,0.8377976417541504
60,0.03692605365545322,0.8950189352035522,0.2934599816799164,0.8348214626312256
61,0.038855401799082756,0.8878250122070312,0.22090551257133484,0.8404762148857117
62,0.03132383749844172,0.8962923288345337,0.25310343503952026,0.8479167222976685
63,0.029155220788640853,0.9052556753158569,0.26264581084251404,0.8440475463867188
64,0.028381262356654193,0.9038500189781189,0.24883460998535156,0.8351190090179443
65,0.029382560545435317,0.9036681056022644,0.23446619510650635,0.8485118746757507
66,0.026988155327928372,0.9126811027526855,0.28346073627471924,0.8467261791229248
67,0.061469702766491816,0.8793577551841736,0.34957778453826904,0.8020833730697632
68,0.13352817325637892,0.8350202441215515,0.31983649730682373,0.7979166507720947
69,0.13277117592784074,0.826337993144989,0.6004314422607422,0.7741071581840515
70,0.49579169505681747,0.7357611060142517,1.3732565641403198,0.6937500834465027
71,1.0972270843310235,0.6766058802604675,1.1254119873046875,0.6752976179122925
72,1.0529832266844237,0.6732155680656433,0.8747549057006836,0.6937500238418579
73,0.6869169955070202,0.7043890953063965,1.3311333656311035,0.682440459728241
74,0.689029954182796,0.7059767246246338,0.9633743166923523,0.7133929133415222
75,0.4593528895041881,0.7329165935516357,0.9559235572814941,0.7178572416305542
76,0.3321344982355069,0.7482470273971558,0.5574339628219604,0.754464328289032
77,0.18806426647381905,0.7755507230758667,0.6076700687408447,0.7729166746139526
78,0.11992574005554883,0.8036152124404907,0.45181816816329956,0.7895833849906921
79,0.08565038203811035,0.8228980898857117,0.4187662899494171,0.8014881014823914
80,0.07286661557662182,0.835665225982666,0.4242314100265503,0.8068453073501587
81,0.06114196146910007,0.847274661064148,0.40132302045822144,0.8127976655960083
82,0.05088931885667336,0.8563703298568726,0.3736618161201477,0.8160714507102966
83,0.04305757233538689,0.8689885139465332,0.3883454203605652,0.8217262029647827
84,0.03884107414155434,0.8772739768028259,0.3742274045944214,0.8238095641136169
85,0.035493459743567005,0.8823014497756958,0.38391560316085815,0.8244048357009888
86,0.03200787009719091,0.8878580927848816,0.3467923402786255,0.8324405550956726
87,0.029151743086866844,0.8942416906356812,0.36490845680236816,0.8375000357627869
88,0.026709028161489047,0.9012205004692078,0.3784771263599396,0.8383929133415222
89,0.02507457275612232,0.9057352542877197,0.3571878671646118,0.8398809432983398
90,0.023661129319897063,0.909687876701355,0.3623684048652649,0.8404762148857117
91,0.021621583674389582,0.9146987199783325,0.3301055431365967,0.8416666984558105
92,0.020549661336609952,0.9191638827323914,0.34186869859695435,0.8428572416305542
93,0.01938887124355787,0.9224383234977722,0.3351489007472992,0.8440476655960083
94,0.01925953733137785,0.9221076369285583,0.32951897382736206,0.8458333015441895
95,0.019179627060508117,0.9229841232299805,0.36478251218795776,0.843154788017273
96,0.020529047490503542,0.924307107925415,0.3590432405471802,0.8461309671401978
97,0.018628226020015203,0.9265727996826172,0.3352550268173218,0.8464285731315613
98,0.018151806213725835,0.9269862174987793,0.3327004313468933,0.8479167222976685
99,0.01744310748882783,0.9280446767807007,0.3542556166648865,0.8505953550338745
epoch,training loss,train accuracy,test loss,test accuracy
0,0.07513890056783497,0.023698486387729645,0.0,0.0
1,0.0,0.0,0.0,0.0
2,0.0,0.0,0.0,0.0
3,0.0,0.0,0.0,0.0
4,0.0,0.0,0.0,0.0
5,0.0,0.0,0.0,0.0
6,0.0,0.0,0.0,0.0
7,0.0,0.0,0.0,0.0
8,0.0,0.0,0.0,0.0
9,0.0,0.0,0.0,0.0
10,0.0,0.0,0.0,0.0
11,0.0,0.0,0.0,0.0
12,0.0,0.0,0.0,0.0
13,0.0,0.0,0.0,0.0
14,0.0,0.0,0.0,0.0
15,0.0,0.0,0.0,0.0
16,0.0,0.0,0.0,0.0
17,0.0,0.0,0.0,0.0
18,0.0,0.0,0.0,0.0
19,0.0,0.0,0.0,0.0
20,0.0,0.0,0.0,0.0
21,0.0,0.0,0.0,0.0
22,0.0,0.0,0.0,0.0
23,0.0,0.0,0.0,0.0
24,0.0,0.0,0.0,0.0
25,0.0,0.0,0.0,0.0
26,0.0,0.0,0.0,0.0
27,0.0,0.0,0.0,0.0
28,0.0,0.0,0.0,0.0
29,0.0,0.0,0.0,0.0
30,0.0,0.0,0.0,0.0
31,0.0,0.0,0.0,0.0
32,0.0,0.0,0.0,0.0
33,0.0,0.0,0.0,0.0
34,0.0,0.0,0.0,0.0
35,0.0,0.0,0.0,0.0
36,0.0,0.0,0.0,0.0
37,0.0,0.0,0.0,0.0
38,0.0,0.0,0.0,0.0
39,0.0,0.0,0.0,0.0
40,0.0,0.0,0.0,0.0
41,0.0,0.0,0.0,0.0
42,0.0,0.0,0.0,0.0
43,0.0,0.0,0.0,0.0
44,0.0,0.0,0.0,0.0
45,0.0,0.0,0.0,0.0
46,0.0,0.0,0.0,0.0
47,0.0,0.0,0.0,0.0
48,0.0,0.0,0.0,0.0
49,0.0,0.0,0.0,0.0
50,0.0,0.0,0.0,0.0
51,0.0,0.0,0.0,0.0
52,0.0,0.0,0.0,0.0
53,0.0,0.0,0.0,0.0
54,0.0,0.0,0.0,0.0
55,0.0,0.0,0.0,0.0
56,0.0,0.0,0.0,0.0
57,0.0,0.0,0.0,0.0
58,0.0,0.0,0.0,0.0
59,0.0,0.0,0.0,0.0
60,0.0,0.0,0.0,0.0
61,0.0,0.0,0.0,0.0
62,0.0,0.0,0.0,0.0
63,0.0,0.0,0.0,0.0
64,0.0,0.0,0.0,0.0
65,0.0,0.0,0.0,0.0
66,0.0,0.0,0.0,0.0
67,0.0,0.0,0.0,0.0
68,0.0,0.0,0.0,0.0
69,0.0,0.0,0.0,0.0
70,0.0,0.0,0.0,0.0
71,0.0,0.0,0.0,0.0
72,0.0,0.0,0.0,0.0
73,0.0,0.0,0.0,0.0
74,0.0,0.0,0.0,0.0
75,0.0,0.0,0.0,0.0
76,0.0,0.0,0.0,0.0
77,0.0,0.0,0.0,0.0
78,0.0,0.0,0.0,0.0
79,0.0,0.0,0.0,0.0
80,0.0,0.0,0.0,0.0
81,0.0,0.0,0.0,0.0
82,0.0,0.0,0.0,0.0
83,0.0,0.0,0.0,0.0
84,0.0,0.0,0.0,0.0
85,0.0,0.0,0.0,0.0
86,0.0,0.0,0.0,0.0
87,0.0,0.0,0.0,0.0
88,0.0,0.0,0.0,0.0
89,0.0,0.0,0.0,0.0
90,0.0,0.0,0.0,0.0
91,0.0,0.0,0.0,0.0
92,0.0,0.0,0.0,0.0
93,0.0,0.0,0.0,0.0
94,0.0,0.0,0.0,0.0
95,0.0,0.0,0.0,0.0
96,0.0,0.0,0.0,0.0
97,0.0,0.0,0.0,0.0
98,0.0,0.0,0.0,0.0
99,0.0,0.0,0.0,0.0
epoch,training loss,train accuracy,test loss,test accuracy
0,3.0436402559280396,0.5748329758644104,5.034055233001709,0.6157737970352173
1,2.7104244996339846,0.5969769358634949,4.5503644943237305,0.5866071581840515
2,2.566020659911327,0.6050804257392883,5.00931453704834,0.5330356955528259
3,2.3032746956898618,0.6031124591827393,2.4677629470825195,0.5806547999382019
4,1.9706989251650298,0.5313223600387573,1.0929114818572998,0.21964286267757416
5,0.08441788196945801,0.009641463868319988,0.0,0.0
6,0.0,0.0,0.0,0.0
7,0.0,0.0,0.0,0.0
8,0.0,0.0,0.0,0.0
9,0.0,0.0,0.0,0.0
10,0.0,0.0,0.0,0.0
11,0.0,0.0,0.0,0.0
12,0.0,0.0,0.0,0.0
13,0.0,0.0,0.0,0.0
14,0.0,0.0,0.0,0.0
15,0.0,0.0,0.0,0.0
16,0.0,0.0,0.0,0.0
17,0.0,0.0,0.0,0.0
18,0.0,0.0,0.0,0.0
19,0.0,0.0,0.0,0.0
20,0.0,0.0,0.0,0.0
21,0.0,0.0,0.0,0.0
22,0.0,0.0,0.0,0.0
23,0.0,0.0,0.0,0.0
24,0.0,0.0,0.0,0.0
25,0.0,0.0,0.0,0.0
26,0.0,0.0,0.0,0.0
27,0.0,0.0,0.0,0.0
28,0.0,0.0,0.0,0.0
29,0.0,0.0,0.0,0.0
30,0.0,0.0,0.0,0.0
31,0.0,0.0,0.0,0.0
32,0.0,0.0,0.0,0.0
33,0.0,0.0,0.0,0.0
34,0.0,0.0,0.0,0.0
35,0.0,0.0,0.0,0.0
36,0.0,0.0,0.0,0.0
37,0.0,0.0,0.0,0.0
38,0.0,0.0,0.0,0.0
39,0.0,0.0,0.0,0.0
40,0.0,0.0,0.0,0.0
41,0.0,0.0,0.0,0.0
42,0.0,0.0,0.0,0.0
43,0.0,0.0,0.0,0.0
44,0.0,0.0,0.0,0.0
45,0.0,0.0,0.0,0.0
46,0.0,0.0,0.0,0.0
47,0.0,0.0,0.0,0.0
48,0.0,0.0,0.0,0.0
49,0.0,0.0,0.0,0.0
50,0.0,0.0,0.0,0.0
51,0.0,0.0,0.0,0.0
52,0.0,0.0,0.0,0.0
53,0.0,0.0,0.0,0.0
54,0.0,0.0,0.0,0.0
55,0.0,0.0,0.0,0.0
56,0.0,0.0,0.0,0.0
57,0.0,0.0,0.0,0.0
58,0.0,0.0,0.0,0.0
59,0.0,0.0,0.0,0.0
60,0.0,0.0,0.0,0.0
61,0.0,0.0,0.0,0.0
62,0.0,0.0,0.0,0.0
63,0.0,0.0,0.0,0.0
64,0.0,0.0,0.0,0.0
65,0.0,0.0,0.0,0.0
66,0.0,0.0,0.0,0.0
67,0.0,0.0,0.0,0.0
68,0.0,0.0,0.0,0.0
69,0.0,0.0,0.0,0.0
70,0.0,0.0,0.0,0.0
71,0.0,0.0,0.0,0.0
72,0.0,0.0,0.0,0.0
73,0.0,0.0,0.0,0.0
74,0.0,0.0,0.0,0.0
75,0.0,0.0,0.0,0.0
76,0.0,0.0,0.0,0.0
77,0.0,0.0,0.0,0.0
78,0.0,0.0,0.0,0.0
79,0.0,0.0,0.0,0.0
80,0.0,0.0,0.0,0.0
81,0.0,0.0,0.0,0.0
82,0.0,0.0,0.0,0.0
83,0.0,0.0,0.0,0.0
84,0.0,0.0,0.0,0.0
85,0.0,0.0,0.0,0.0
86,0.0,0.0,0.0,0.0
87,0.0,0.0,0.0,0.0
88,0.0,0.0,0.0,0.0
89,0.0,0.0,0.0,0.0
90,0.0,0.0,0.0,0.0
91,0.0,0.0,0.0,0.0
92,0.0,0.0,0.0,0.0
93,0.0,0.0,0.0,0.0
94,0.0,0.0,0.0,0.0
95,0.0,0.0,0.0,0.0
96,0.0,0.0,0.0,0.0
97,0.0,0.0,0.0,0.0
98,0.0,0.0,0.0,0.0
99,0.0,0.0,0.0,0.0
epoch,training loss,train accuracy,test loss,test accuracy
0,2.6805123060177536,0.45132964849472046,0.8499617576599121,0.05386904999613762
1,0.02404674235664571,0.0016537674237042665,0.0,0.0
2,0.0,0.0,0.0,0.0
3,0.0,0.0,0.0,0.0
4,0.0,0.0,0.0,0.0
5,0.0,0.0,0.0,0.0
6,0.0,0.0,0.0,0.0
7,0.0,0.0,0.0,0.0
8,0.0,0.0,0.0,0.0
9,0.0,0.0,0.0,0.0
10,0.0,0.0,0.0,0.0
11,0.0,0.0,0.0,0.0
12,0.0,0.0,0.0,0.0
13,0.0,0.0,0.0,0.0
14,0.0,0.0,0.0,0.0
15,0.0,0.0,0.0,0.0
16,0.0,0.0,0.0,0.0
17,0.0,0.0,0.0,0.0
18,0.0,0.0,0.0,0.0
19,0.0,0.0,0.0,0.0
20,0.0,0.0,0.0,0.0
21,0.0,0.0,0.0,0.0
22,0.0,0.0,0.0,0.0
23,0.0,0.0,0.0,0.0
24,0.0,0.0,0.0,0.0
25,0.0,0.0,0.0,0.0
26,0.0,0.0,0.0,0.0
27,0.0,0.0,0.0,0.0
28,0.0,0.0,0.0,0.0
29,0.0,0.0,0.0,0.0
30,0.0,0.0,0.0,0.0
31,0.0,0.0,0.0,0.0
32,0.0,0.0,0.0,0.0
33,0.0,0.0,0.0,0.0
34,0.0,0.0,0.0,0.0
35,0.0,0.0,0.0,0.0
36,0.0,0.0,0.0,0.0
37,0.0,0.0,0.0,0.0
38,0.0,0.0,0.0,0.0
39,0.0,0.0,0.0,0.0
40,0.0,0.0,0.0,0.0
41,0.0,0.0,0.0,0.0
42,0.0,0.0,0.0,0.0
43,0.0,0.0,0.0,0.0
44,0.0,0.0,0.0,0.0
45,0.0,0.0,0.0,0.0
46,0.0,0.0,0.0,0.0
47,0.0,0.0,0.0,0.0
48,0.0,0.0,0.0,0.0
49,0.0,0.0,0.0,0.0
50,0.0,0.0,0.0,0.0
51,0.0,0.0,0.0,0.0
52,0.0,0.0,0.0,0.0
53,0.0,0.0,0.0,0.0
54,0.0,0.0,0.0,0.0
55,0.0,0.0,0.0,0.0
56,0.0,0.0,0.0,0.0
57,0.0,0.0,0.0,0.0
58,0.0,0.0,0.0,0.0
59,0.0,0.0,0.0,0.0
60,0.0,0.0,0.0,0.0
61,0.0,0.0,0.0,0.0
62,0.0,0.0,0.0,0.0
63,0.0,0.0,0.0,0.0
64,0.0,0.0,0.0,0.0
65,0.0,0.0,0.0,0.0
66,0.0,0.0,0.0,0.0
67,0.0,0.0,0.0,0.0
68,0.0,0.0,0.0,0.0
69,0.0,0.0,0.0,0.0
70,0.0,0.0,0.0,0.0
71,0.0,0.0,0.0,0.0
72,0.0,0.0,0.0,0.0
73,0.0,0.0,0.0,0.0
74,0.0,0.0,0.0,0.0
75,0.0,0.0,0.0,0.0
76,0.0,0.0,0.0,0.0
77,0.0,0.0,0.0,0.0
78,0.0,0.0,0.0,0.0
79,0.0,0.0,0.0,0.0
80,0.0,0.0,0.0,0.0
81,0.0,0.0,0.0,0.0
82,0.0,0.0,0.0,0.0
83,0.0,0.0,0.0,0.0
84,0.0,0.0,0.0,0.0
85,0.0,0.0,0.0,0.0
86,0.0,0.0,0.0,0.0
87,0.0,0.0,0.0,0.0
88,0.0,0.0,0.0,0.0
89,0.0,0.0,0.0,0.0
90,0.0,0.0,0.0,0.0
91,0.0,0.0,0.0,0.0
92,0.0,0.0,0.0,0.0
93,0.0,0.0,0.0,0.0
94,0.0,0.0,0.0,0.0
95,0.0,0.0,0.0,0.0
96,0.0,0.0,0.0,0.0
97,0.0,0.0,0.0,0.0
98,0.0,0.0,0.0,0.0
99,0.0,0.0,0.0,0.0
epoch,training loss,train accuracy,test loss,test accuracy
0,3.073838649651943,0.5819607377052307,5.073732376098633,0.6389881372451782
1,2.717913419772417,0.6057088375091553,4.839810371398926,0.6205357313156128
2,2.3587887348272862,0.6108520030975342,4.336860656738281,0.6383928656578064
3,2.2458946521465597,0.6173348426818848,4.5542097091674805,0.6166666746139526
4,2.0416322426918225,0.615201473236084,2.4322357177734375,0.6041666865348816
5,2.015867902682378,0.6011940240859985,2.2525734901428223,0.6166667342185974
6,0.619755283380166,0.10173976421356201,0.0,0.0
7,0.0,0.0,0.0,0.0
8,0.0,0.0,0.0,0.0
9,0.0,0.0,0.0,0.0
10,0.0,0.0,0.0,0.0
11,0.0,0.0,0.0,0.0
12,0.0,0.0,0.0,0.0
13,0.0,0.0,0.0,0.0
14,0.0,0.0,0.0,0.0
15,0.0,0.0,0.0,0.0
16,0.0,0.0,0.0,0.0
17,0.0,0.0,0.0,0.0
18,0.0,0.0,0.0,0.0
19,0.0,0.0,0.0,0.0
20,0.0,0.0,0.0,0.0
21,0.0,0.0,0.0,0.0
22,0.0,0.0,0.0,0.0
23,0.0,0.0,0.0,0.0
24,0.0,0.0,0.0,0.0
25,0.0,0.0,0.0,0.0
26,0.0,0.0,0.0,0.0
27,0.0,0.0,0.0,0.0
28,0.0,0.0,0.0,0.0
29,0.0,0.0,0.0,0.0
30,0.0,0.0,0.0,0.0
31,0.0,0.0,0.0,0.0
32,0.0,0.0,0.0,0.0
33,0.0,0.0,0.0,0.0
34,0.0,0.0,0.0,0.0
35,0.0,0.0,0.0,0.0
36,0.0,0.0,0.0,0.0
37,0.0,0.0,0.0,0.0
38,0.0,0.0,0.0,0.0
39,0.0,0.0,0.0,0.0
40,0.0,0.0,0.0,0.0
41,0.0,0.0,0.0,0.0
42,0.0,0.0,0.0,0.0
43,0.0,0.0,0.0,0.0
44,0.0,0.0,0.0,0.0
45,0.0,0.0,0.0,0.0
46,0.0,0.0,0.0,0.0
47,0.0,0.0,0.0,0.0
48,0.0,0.0,0.0,0.0
49,0.0,0.0,0.0,0.0
50,0.0,0.0,0.0,0.0
51,0.0,0.0,0.0,0.0
52,0.0,0.0,0.0,0.0
53,0.0,0.0,0.0,0.0
54,0.0,0.0,0.0,0.0
55,0.0,0.0,0.0,0.0
56,0.0,0.0,0.0,0.0
57,0.0,0.0,0.0,0.0
58,0.0,0.0,0.0,0.0
59,0.0,0.0,0.0,0.0
60,0.0,0.0,0.0,0.0
61,0.0,0.0,0.0,0.0
62,0.0,0.0,0.0,0.0
63,0.0,0.0,0.0,0.0
64,0.0,0.0,0.0,0.0
65,0.0,0.0,0.0,0.0
66,0.0,0.0,0.0,0.0
67,0.0,0.0,0.0,0.0
68,0.0,0.0,0.0,0.0
69,0.0,0.0,0.0,0.0
70,0.0,0.0,0.0,0.0
71,0.0,0.0,0.0,0.0
72,0.0,0.0,0.0,0.0
73,0.0,0.0,0.0,0.0
74,0.0,0.0,0.0,0.0
75,0.0,0.0,0.0,0.0
76,0.0,0.0,0.0,0.0
77,0.0,0.0,0.0,0.0
78,0.0,0.0,0.0,0.0
79,0.0,0.0,0.0,0.0
80,0.0,0.0,0.0,0.0
81,0.0,0.0,0.0,0.0
82,0.0,0.0,0.0,0.0
83,0.0,0.0,0.0,0.0
84,0.0,0.0,0.0,0.0
85,0.0,0.0,0.0,0.0
86,0.0,0.0,0.0,0.0
87,0.0,0.0,0.0,0.0
88,0.0,0.0,0.0,0.0
89,0.0,0.0,0.0,0.0
90,0.0,0.0,0.0,0.0
91,0.0,0.0,0.0,0.0
92,0.0,0.0,0.0,0.0
93,0.0,0.0,0.0,0.0
94,0.0,0.0,0.0,0.0
95,0.0,0.0,0.0,0.0
96,0.0,0.0,0.0,0.0
97,0.0,0.0,0.0,0.0
98,0.0,0.0,0.0,0.0
99,0.0,0.0,0.0,0.0
epoch,training loss,train accuracy,test loss,test accuracy
0,0.21686077467987142,0.03512601926922798,0.0,0.0
1,0.0,0.0,0.0,0.0
2,0.0,0.0,0.0,0.0
3,0.0,0.0,0.0,0.0
4,0.0,0.0,0.0,0.0
5,0.0,0.0,0.0,0.0
6,0.0,0.0,0.0,0.0
7,0.0,0.0,0.0,0.0
8,0.0,0.0,0.0,0.0
9,0.0,0.0,0.0,0.0
10,0.0,0.0,0.0,0.0
11,0.0,0.0,0.0,0.0
12,0.0,0.0,0.0,0.0
13,0.0,0.0,0.0,0.0
14,0.0,0.0,0.0,0.0
15,0.0,0.0,0.0,0.0
16,0.0,0.0,0.0,0.0
17,0.0,0.0,0.0,0.0
18,0.0,0.0,0.0,0.0
19,0.0,0.0,0.0,0.0
20,0.0,0.0,0.0,0.0
21,0.0,0.0,0.0,0.0
22,0.0,0.0,0.0,0.0
23,0.0,0.0,0.0,0.0
24,0.0,0.0,0.0,0.0
25,0.0,0.0,0.0,0.0
26,0.0,0.0,0.0,0.0
27,0.0,0.0,0.0,0.0
28,0.0,0.0,0.0,0.0
29,0.0,0.0,0.0,0.0
30,0.0,0.0,0.0,0.0
31,0.0,0.0,0.0,0.0
32,0.0,0.0,0.0,0.0
33,0.0,0.0,0.0,0.0
34,0.0,0.0,0.0,0.0
35,0.0,0.0,0.0,0.0
36,0.0,0.0,0.0,0.0
37,0.0,0.0,0.0,0.0
38,0.0,0.0,0.0,0.0
39,0.0,0.0,0.0,0.0
40,0.0,0.0,0.0,0.0
41,0.0,0.0,0.0,0.0
42,0.0,0.0,0.0,0.0
43,0.0,0.0,0.0,0.0
44,0.0,0.0,0.0,0.0
45,0.0,0.0,0.0,0.0
46,0.0,0.0,0.0,0.0
47,0.0,0.0,0.0,0.0
48,0.0,0.0,0.0,0.0
49,0.0,0.0,0.0,0.0
50,0.0,0.0,0.0,0.0
51,0.0,0.0,0.0,0.0
52,0.0,0.0,0.0,0.0
53,0.0,0.0,0.0,0.0
54,0.0,0.0,0.0,0.0
55,0.0,0.0,0.0,0.0
56,0.0,0.0,0.0,0.0
57,0.0,0.0,0.0,0.0
58,0.0,0.0,0.0,0.0
59,0.0,0.0,0.0,0.0
60,0.0,0.0,0.0,0.0
61,0.0,0.0,0.0,0.0
62,0.0,0.0,0.0,0.0
63,0.0,0.0,0.0,0.0
64,0.0,0.0,0.0,0.0
65,0.0,0.0,0.0,0.0
66,0.0,0.0,0.0,0.0
67,0.0,0.0,0.0,0.0
68,0.0,0.0,0.0,0.0
69,0.0,0.0,0.0,0.0
70,0.0,0.0,0.0,0.0
71,0.0,0.0,0.0,0.0
72,0.0,0.0,0.0,0.0
73,0.0,0.0,0.0,0.0
74,0.0,0.0,0.0,0.0
75,0.0,0.0,0.0,0.0
76,0.0,0.0,0.0,0.0
77,0.0,0.0,0.0,0.0
78,0.0,0.0,0.0,0.0
79,0.0,0.0,0.0,0.0
80,0.0,0.0,0.0,0.0
81,0.0,0.0,0.0,0.0
82,0.0,0.0,0.0,0.0
83,0.0,0.0,0.0,0.0
84,0.0,0.0,0.0,0.0
85,0.0,0.0,0.0,0.0
86,0.0,0.0,0.0,0.0
87,0.0,0.0,0.0,0.0
88,0.0,0.0,0.0,0.0
89,0.0,0.0,0.0,0.0
90,0.0,0.0,0.0,0.0
91,0.0,0.0,0.0,0.0
92,0.0,0.0,0.0,0.0
93,0.0,0.0,0.0,0.0
94,0.0,0.0,0.0,0.0
95,0.0,0.0,0.0,0.0
96,0.0,0.0,0.0,0.0
97,0.0,0.0,0.0,0.0
98,0.0,0.0,0.0,0.0
99,0.0,0.0,0.0,0.0
epoch,training loss,train accuracy,test loss,test accuracy
0,0.09515617915355132,0.031322356313467026,0.0,0.0
1,0.0,0.0,0.0,0.0
2,0.0,0.0,0.0,0.0
3,0.0,0.0,0.0,0.0
4,0.0,0.0,0.0,0.0
5,0.0,0.0,0.0,0.0
6,0.0,0.0,0.0,0.0
7,0.0,0.0,0.0,0.0
8,0.0,0.0,0.0,0.0
9,0.0,0.0,0.0,0.0
10,0.0,0.0,0.0,0.0
11,0.0,0.0,0.0,0.0
12,0.0,0.0,0.0,0.0
13,0.0,0.0,0.0,0.0
14,0.0,0.0,0.0,0.0
15,0.0,0.0,0.0,0.0
16,0.0,0.0,0.0,0.0
17,0.0,0.0,0.0,0.0
18,0.0,0.0,0.0,0.0
19,0.0,0.0,0.0,0.0
20,0.0,0.0,0.0,0.0
21,0.0,0.0,0.0,0.0
22,0.0,0.0,0.0,0.0
23,0.0,0.0,0.0,0.0
24,0.0,0.0,0.0,0.0
25,0.0,0.0,0.0,0.0
26,0.0,0.0,0.0,0.0
27,0.0,0.0,0.0,0.0
28,0.0,0.0,0.0,0.0
29,0.0,0.0,0.0,0.0
30,0.0,0.0,0.0,0.0
31,0.0,0.0,0.0,0.0
32,0.0,0.0,0.0,0.0
33,0.0,0.0,0.0,0.0
34,0.0,0.0,0.0,0.0
35,0.0,0.0,0.0,0.0
36,0.0,0.0,0.0,0.0
37,0.0,0.0,0.0,0.0
38,0.0,0.0,0.0,0.0
39,0.0,0.0,0.0,0.0
40,0.0,0.0,0.0,0.0
41,0.0,0.0,0.0,0.0
42,0.0,0.0,0.0,0.0
43,0.0,0.0,0.0,0.0
44,0.0,0.0,0.0,0.0
45,0.0,0.0,0.0,0.0
46,0.0,0.0,0.0,0.0
47,0.0,0.0,0.0,0.0
48,0.0,0.0,0.0,0.0
49,0.0,0.0,0.0,0.0
50,0.0,0.0,0.0,0.0
51,0.0,0.0,0.0,0.0
52,0.0,0.0,0.0,0.0
53,0.0,0.0,0.0,0.0
54,0.0,0.0,0.0,0.0
55,0.0,0.0,0.0,0.0
56,0.0,0.0,0.0,0.0
57,0.0,0.0,0.0,0.0
58,0.0,0.0,0.0,0.0
59,0.0,0.0,0.0,0.0
60,0.0,0.0,0.0,0.0
61,0.0,0.0,0.0,0.0
62,0.0,0.0,0.0,0.0
63,0.0,0.0,0.0,0.0
64,0.0,0.0,0.0,0.0
65,0.0,0.0,0.0,0.0
66,0.0,0.0,0.0,0.0
67,0.0,0.0,0.0,0.0
68,0.0,0.0,0.0,0.0
69,0.0,0.0,0.0,0.0
70,0.0,0.0,0.0,0.0
71,0.0,0.0,0.0,0.0
72,0.0,0.0,0.0,0.0
73,0.0,0.0,0.0,0.0
74,0.0,0.0,0.0,0.0
75,0.0,0.0,0.0,0.0
76,0.0,0.0,0.0,0.0
77,0.0,0.0,0.0,0.0
78,0.0,0.0,0.0,0.0
79,0.0,0.0,0.0,0.0
80,0.0,0.0,0.0,0.0
81,0.0,0.0,0.0,0.0
82,0.0,0.0,0.0,0.0
83,0.0,0.0,0.0,0.0
84,0.0,0.0,0.0,0.0
85,0.0,0.0,0.0,0.0
86,0.0,0.0,0.0,0.0
87,0.0,0.0,0.0,0.0
88,0.0,0.0,0.0,0.0
89,0.0,0.0,0.0,0.0
90,0.0,0.0,0.0,0.0
91,0.0,0.0,0.0,0.0
92,0.0,0.0,0.0,0.0
93,0.0,0.0,0.0,0.0
94,0.0,0.0,0.0,0.0
95,0.0,0.0,0.0,0.0
96,0.0,0.0,0.0,0.0
97,0.0,0.0,0.0,0.0
98,0.0,0.0,0.0,0.0
99,0.0,0.0,0.0,0.0
epoch,training loss,train accuracy,test loss,test accuracy
0,0.10937751398042743,0.033984921872615814,0.0,0.0
1,0.0,0.0,0.0,0.0
2,0.0,0.0,0.0,0.0
3,0.0,0.0,0.0,0.0
4,0.0,0.0,0.0,0.0
5,0.0,0.0,0.0,0.0
6,0.0,0.0,0.0,0.0
7,0.0,0.0,0.0,0.0
8,0.0,0.0,0.0,0.0
9,0.0,0.0,0.0,0.0
10,0.0,0.0,0.0,0.0
11,0.0,0.0,0.0,0.0
12,0.0,0.0,0.0,0.0
13,0.0,0.0,0.0,0.0
14,0.0,0.0,0.0,0.0
15,0.0,0.0,0.0,0.0
16,0.0,0.0,0.0,0.0
17,0.0,0.0,0.0,0.0
18,0.0,0.0,0.0,0.0
19,0.0,0.0,0.0,0.0
20,0.0,0.0,0.0,0.0
21,0.0,0.0,0.0,0.0
22,0.0,0.0,0.0,0.0
23,0.0,0.0,0.0,0.0
24,0.0,0.0,0.0,0.0
25,0.0,0.0,0.0,0.0
26,0.0,0.0,0.0,0.0
27,0.0,0.0,0.0,0.0
28,0.0,0.0,0.0,0.0
29,0.0,0.0,0.0,0.0
30,0.0,0.0,0.0,0.0
31,0.0,0.0,0.0,0.0
32,0.0,0.0,0.0,0.0
33,0.0,0.0,0.0,0.0
34,0.0,0.0,0.0,0.0
35,0.0,0.0,0.0,0.0
36,0.0,0.0,0.0,0.0
37,0.0,0.0,0.0,0.0
38,0.0,0.0,0.0,0.0
39,0.0,0.0,0.0,0.0
40,0.0,0.0,0.0,0.0
41,0.0,0.0,0.0,0.0
42,0.0,0.0,0.0,0.0
43,0.0,0.0,0.0,0.0
44,0.0,0.0,0.0,0.0
45,0.0,0.0,0.0,0.0
46,0.0,0.0,0.0,0.0
47,0.0,0.0,0.0,0.0
48,0.0,0.0,0.0,0.0
49,0.0,0.0,0.0,0.0
50,0.0,0.0,0.0,0.0
51,0.0,0.0,0.0,0.0
52,0.0,0.0,0.0,0.0
53,0.0,0.0,0.0,0.0
54,0.0,0.0,0.0,0.0
55,0.0,0.0,0.0,0.0
56,0.0,0.0,0.0,0.0
57,0.0,0.0,0.0,0.0
58,0.0,0.0,0.0,0.0
59,0.0,0.0,0.0,0.0
60,0.0,0.0,0.0,0.0
61,0.0,0.0,0.0,0.0
62,0.0,0.0,0.0,0.0
63,0.0,0.0,0.0,0.0
64,0.0,0.0,0.0,0.0
65,0.0,0.0,0.0,0.0
66,0.0,0.0,0.0,0.0
67,0.0,0.0,0.0,0.0
68,0.0,0.0,0.0,0.0
69,0.0,0.0,0.0,0.0
70,0.0,0.0,0.0,0.0
71,0.0,0.0,0.0,0.0
72,0.0,0.0,0.0,0.0
73,0.0,0.0,0.0,0.0
74,0.0,0.0,0.0,0.0
75,0.0,0.0,0.0,0.0
76,0.0,0.0,0.0,0.0
77,0.0,0.0,0.0,0.0
78,0.0,0.0,0.0,0.0
79,0.0,0.0,0.0,0.0
80,0.0,0.0,0.0,0.0
81,0.0,0.0,0.0,0.0
82,0.0,0.0,0.0,0.0
83,0.0,0.0,0.0,0.0
84,0.0,0.0,0.0,0.0
85,0.0,0.0,0.0,0.0
86,0.0,0.0,0.0,0.0
87,0.0,0.0,0.0,0.0
88,0.0,0.0,0.0,0.0
89,0.0,0.0,0.0,0.0
90,0.0,0.0,0.0,0.0
91,0.0,0.0,0.0,0.0
92,0.0,0.0,0.0,0.0
93,0.0,0.0,0.0,0.0
94,0.0,0.0,0.0,0.0
95,0.0,0.0,0.0,0.0
96,0.0,0.0,0.0,0.0
97,0.0,0.0,0.0,0.0
98,0.0,0.0,0.0,0.0
99,0.0,0.0,0.0,0.0
epoch,training loss,train accuracy,test loss,test accuracy
0,0.09437073319072507,0.022673150524497032,0.0,0.0
1,0.0,0.0,0.0,0.0
2,0.0,0.0,0.0,0.0
3,0.0,0.0,0.0,0.0
4,0.0,0.0,0.0,0.0
5,0.0,0.0,0.0,0.0
6,0.0,0.0,0.0,0.0
7,0.0,0.0,0.0,0.0
8,0.0,0.0,0.0,0.0
9,0.0,0.0,0.0,0.0
10,0.0,0.0,0.0,0.0
11,0.0,0.0,0.0,0.0
12,0.0,0.0,0.0,0.0
13,0.0,0.0,0.0,0.0
14,0.0,0.0,0.0,0.0
15,0.0,0.0,0.0,0.0
16,0.0,0.0,0.0,0.0
17,0.0,0.0,0.0,0.0
18,0.0,0.0,0.0,0.0
19,0.0,0.0,0.0,0.0
20,0.0,0.0,0.0,0.0
21,0.0,0.0,0.0,0.0
22,0.0,0.0,0.0,0.0
23,0.0,0.0,0.0,0.0
24,0.0,0.0,0.0,0.0
25,0.0,0.0,0.0,0.0
26,0.0,0.0,0.0,0.0
27,0.0,0.0,0.0,0.0
28,0.0,0.0,0.0,0.0
29,0.0,0.0,0.0,0.0
30,0.0,0.0,0.0,0.0
31,0.0,0.0,0.0,0.0
32,0.0,0.0,0.0,0.0
33,0.0,0.0,0.0,0.0
34,0.0,0.0,0.0,0.0
35,0.0,0.0,0.0,0.0
36,0.0,0.0,0.0,0.0
37,0.0,0.0,0.0,0.0
38,0.0,0.0,0.0,0.0
39,0.0,0.0,0.0,0.0
40,0.0,0.0,0.0,0.0
41,0.0,0.0,0.0,0.0
42,0.0,0.0,0.0,0.0
43,0.0,0.0,0.0,0.0
44,0.0,0.0,0.0,0.0
45,0.0,0.0,0.0,0.0
46,0.0,0.0,0.0,0.0
47,0.0,0.0,0.0,0.0
48,0.0,0.0,0.0,0.0
49,0.0,0.0,0.0,0.0
50,0.0,0.0,0.0,0.0
51,0.0,0.0,0.0,0.0
52,0.0,0.0,0.0,0.0
53,0.0,0.0,0.0,0.0
54,0.0,0.0,0.0,0.0
55,0.0,0.0,0.0,0.0
56,0.0,0.0,0.0,0.0
57,0.0,0.0,0.0,0.0
58,0.0,0.0,0.0,0.0
59,0.0,0.0,0.0,0.0
60,0.0,0.0,0.0,0.0
61,0.0,0.0,0.0,0.0
62,0.0,0.0,0.0,0.0
63,0.0,0.0,0.0,0.0
64,0.0,0.0,0.0,0.0
65,0.0,0.0,0.0,0.0
66,0.0,0.0,0.0,0.0
67,0.0,0.0,0.0,0.0
68,0.0,0.0,0.0,0.0
69,0.0,0.0,0.0,0.0
70,0.0,0.0,0.0,0.0
71,0.0,0.0,0.0,0.0
72,0.0,0.0,0.0,0.0
73,0.0,0.0,0.0,0.0
74,0.0,0.0,0.0,0.0
75,0.0,0.0,0.0,0.0
76,0.0,0.0,0.0,0.0
77,0.0,0.0,0.0,0.0
78,0.0,0.0,0.0,0.0
79,0.0,0.0,0.0,0.0
80,0.0,0.0,0.0,0.0
81,0.0,0.0,0.0,0.0
82,0.0,0.0,0.0,0.0
83,0.0,0.0,0.0,0.0
84,0.0,0.0,0.0,0.0
85,0.0,0.0,0.0,0.0
86,0.0,0.0,0.0,0.0
87,0.0,0.0,0.0,0.0
88,0.0,0.0,0.0,0.0
89,0.0,0.0,0.0,0.0
90,0.0,0.0,0.0,0.0
91,0.0,0.0,0.0,0.0
92,0.0,0.0,0.0,0.0
93,0.0,0.0,0.0,0.0
94,0.0,0.0,0.0,0.0
95,0.0,0.0,0.0,0.0
96,0.0,0.0,0.0,0.0
97,0.0,0.0,0.0,0.0
98,0.0,0.0,0.0,0.0
99,0.0,0.0,0.0,0.0
epoch,training loss,train accuracy,test loss,test accuracy
0,0.05732161647055323,0.018026065081357956,0.0,0.0
1,0.0,0.0,0.0,0.0
2,0.0,0.0,0.0,0.0
3,0.0,0.0,0.0,0.0
4,0.0,0.0,0.0,0.0
5,0.0,0.0,0.0,0.0
6,0.0,0.0,0.0,0.0
7,0.0,0.0,0.0,0.0
8,0.0,0.0,0.0,0.0
9,0.0,0.0,0.0,0.0
10,0.0,0.0,0.0,0.0
11,0.0,0.0,0.0,0.0
12,0.0,0.0,0.0,0.0
13,0.0,0.0,0.0,0.0
14,0.0,0.0,0.0,0.0
15,0.0,0.0,0.0,0.0
16,0.0,0.0,0.0,0.0
17,0.0,0.0,0.0,0.0
18,0.0,0.0,0.0,0.0
19,0.0,0.0,0.0,0.0
20,0.0,0.0,0.0,0.0
21,0.0,0.0,0.0,0.0
22,0.0,0.0,0.0,0.0
23,0.0,0.0,0.0,0.0
24,0.0,0.0,0.0,0.0
25,0.0,0.0,0.0,0.0
26,0.0,0.0,0.0,0.0
27,0.0,0.0,0.0,0.0
28,0.0,0.0,0.0,0.0
29,0.0,0.0,0.0,0.0
30,0.0,0.0,0.0,0.0
31,0.0,0.0,0.0,0.0
32,0.0,0.0,0.0,0.0
33,0.0,0.0,0.0,0.0
34,0.0,0.0,0.0,0.0
35,0.0,0.0,0.0,0.0
36,0.0,0.0,0.0,0.0
37,0.0,0.0,0.0,0.0
38,0.0,0.0,0.0,0.0
39,0.0,0.0,0.0,0.0
40,0.0,0.0,0.0,0.0
41,0.0,0.0,0.0,0.0
42,0.0,0.0,0.0,0.0
43,0.0,0.0,0.0,0.0
44,0.0,0.0,0.0,0.0
45,0.0,0.0,0.0,0.0
46,0.0,0.0,0.0,0.0
47,0.0,0.0,0.0,0.0
48,0.0,0.0,0.0,0.0
49,0.0,0.0,0.0,0.0
50,0.0,0.0,0.0,0.0
51,0.0,0.0,0.0,0.0
52,0.0,0.0,0.0,0.0
53,0.0,0.0,0.0,0.0
54,0.0,0.0,0.0,0.0
55,0.0,0.0,0.0,0.0
56,0.0,0.0,0.0,0.0
57,0.0,0.0,0.0,0.0
58,0.0,0.0,0.0,0.0
59,0.0,0.0,0.0,0.0
60,0.0,0.0,0.0,0.0
61,0.0,0.0,0.0,0.0
62,0.0,0.0,0.0,0.0
63,0.0,0.0,0.0,0.0
64,0.0,0.0,0.0,0.0
65,0.0,0.0,0.0,0.0
66,0.0,0.0,0.0,0.0
67,0.0,0.0,0.0,0.0
68,0.0,0.0,0.0,0.0
69,0.0,0.0,0.0,0.0
70,0.0,0.0,0.0,0.0
71,0.0,0.0,0.0,0.0
72,0.0,0.0,0.0,0.0
73,0.0,0.0,0.0,0.0
74,0.0,0.0,0.0,0.0
75,0.0,0.0,0.0,0.0
76,0.0,0.0,0.0,0.0
77,0.0,0.0,0.0,0.0
78,0.0,0.0,0.0,0.0
79,0.0,0.0,0.0,0.0
80,0.0,0.0,0.0,0.0
81,0.0,0.0,0.0,0.0
82,0.0,0.0,0.0,0.0
83,0.0,0.0,0.0,0.0
84,0.0,0.0,0.0,0.0
85,0.0,0.0,0.0,0.0
86,0.0,0.0,0.0,0.0
87,0.0,0.0,0.0,0.0
88,0.0,0.0,0.0,0.0
89,0.0,0.0,0.0,0.0
90,0.0,0.0,0.0,0.0
91,0.0,0.0,0.0,0.0
92,0.0,0.0,0.0,0.0
93,0.0,0.0,0.0,0.0
94,0.0,0.0,0.0,0.0
95,0.0,0.0,0.0,0.0
96,0.0,0.0,0.0,0.0
97,0.0,0.0,0.0,0.0
98,0.0,0.0,0.0,0.0
99,0.0,0.0,0.0,0.0
epoch,training loss,train accuracy,test loss,test accuracy
0,0.25856537224177895,0.03835086524486542,0.0,0.0
1,0.0,0.0,0.0,0.0
2,0.0,0.0,0.0,0.0
3,0.0,0.0,0.0,0.0
4,0.0,0.0,0.0,0.0
5,0.0,0.0,0.0,0.0
6,0.0,0.0,0.0,0.0
7,0.0,0.0,0.0,0.0
8,0.0,0.0,0.0,0.0
9,0.0,0.0,0.0,0.0
10,0.0,0.0,0.0,0.0
11,0.0,0.0,0.0,0.0
12,0.0,0.0,0.0,0.0
13,0.0,0.0,0.0,0.0
14,0.0,0.0,0.0,0.0
15,0.0,0.0,0.0,0.0
16,0.0,0.0,0.0,0.0
17,0.0,0.0,0.0,0.0
18,0.0,0.0,0.0,0.0
19,0.0,0.0,0.0,0.0
20,0.0,0.0,0.0,0.0
21,0.0,0.0,0.0,0.0
22,0.0,0.0,0.0,0.0
23,0.0,0.0,0.0,0.0
24,0.0,0.0,0.0,0.0
25,0.0,0.0,0.0,0.0
26,0.0,0.0,0.0,0.0
27,0.0,0.0,0.0,0.0
28,0.0,0.0,0.0,0.0
29,0.0,0.0,0.0,0.0
30,0.0,0.0,0.0,0.0
31,0.0,0.0,0.0,0.0
32,0.0,0.0,0.0,0.0
33,0.0,0.0,0.0,0.0
34,0.0,0.0,0.0,0.0
35,0.0,0.0,0.0,0.0
36,0.0,0.0,0.0,0.0
37,0.0,0.0,0.0,0.0
38,0.0,0.0,0.0,0.0
39,0.0,0.0,0.0,0.0
40,0.0,0.0,0.0,0.0
41,0.0,0.0,0.0,0.0
42,0.0,0.0,0.0,0.0
43,0.0,0.0,0.0,0.0
44,0.0,0.0,0.0,0.0
45,0.0,0.0,0.0,0.0
46,0.0,0.0,0.0,0.0
47,0.0,0.0,0.0,0.0
48,0.0,0.0,0.0,0.0
49,0.0,0.0,0.0,0.0
50,0.0,0.0,0.0,0.0
51,0.0,0.0,0.0,0.0
52,0.0,0.0,0.0,0.0
53,0.0,0.0,0.0,0.0
54,0.0,0.0,0.0,0.0
55,0.0,0.0,0.0,0.0
56,0.0,0.0,0.0,0.0
57,0.0,0.0,0.0,0.0
58,0.0,0.0,0.0,0.0
59,0.0,0.0,0.0,0.0
60,0.0,0.0,0.0,0.0
61,0.0,0.0,0.0,0.0
62,0.0,0.0,0.0,0.0
63,0.0,0.0,0.0,0.0
64,0.0,0.0,0.0,0.0
65,0.0,0.0,0.0,0.0
66,0.0,0.0,0.0,0.0
67,0.0,0.0,0.0,0.0
68,0.0,0.0,0.0,0.0
69,0.0,0.0,0.0,0.0
70,0.0,0.0,0.0,0.0
71,0.0,0.0,0.0,0.0
72,0.0,0.0,0.0,0.0
73,0.0,0.0,0.0,0.0
74,0.0,0.0,0.0,0.0
75,0.0,0.0,0.0,0.0
76,0.0,0.0,0.0,0.0
77,0.0,0.0,0.0,0.0
78,0.0,0.0,0.0,0.0
79,0.0,0.0,0.0,0.0
80,0.0,0.0,0.0,0.0
81,0.0,0.0,0.0,0.0
82,0.0,0.0,0.0,0.0
83,0.0,0.0,0.0,0.0
84,0.0,0.0,0.0,0.0
85,0.0,0.0,0.0,0.0
86,0.0,0.0,0.0,0.0
87,0.0,0.0,0.0,0.0
88,0.0,0.0,0.0,0.0
89,0.0,0.0,0.0,0.0
90,0.0,0.0,0.0,0.0
91,0.0,0.0,0.0,0.0
92,0.0,0.0,0.0,0.0
93,0.0,0.0,0.0,0.0
94,0.0,0.0,0.0,0.0
95,0.0,0.0,0.0,0.0
96,0.0,0.0,0.0,0.0
97,0.0,0.0,0.0,0.0
98,0.0,0.0,0.0,0.0
99,0.0,0.0,0.0,0.0
epoch,training loss,train accuracy,test loss,test accuracy
0,0.07332273430689853,0.02927168272435665,0.0,0.0
1,0.0,0.0,0.0,0.0
2,0.0,0.0,0.0,0.0
3,0.0,0.0,0.0,0.0
4,0.0,0.0,0.0,0.0
5,0.0,0.0,0.0,0.0
6,0.0,0.0,0.0,0.0
7,0.0,0.0,0.0,0.0
8,0.0,0.0,0.0,0.0
9,0.0,0.0,0.0,0.0
10,0.0,0.0,0.0,0.0
11,0.0,0.0,0.0,0.0
12,0.0,0.0,0.0,0.0
13,0.0,0.0,0.0,0.0
14,0.0,0.0,0.0,0.0
15,0.0,0.0,0.0,0.0
16,0.0,0.0,0.0,0.0
17,0.0,0.0,0.0,0.0
18,0.0,0.0,0.0,0.0
19,0.0,0.0,0.0,0.0
20,0.0,0.0,0.0,0.0
21,0.0,0.0,0.0,0.0
22,0.0,0.0,0.0,0.0
23,0.0,0.0,0.0,0.0
24,0.0,0.0,0.0,0.0
25,0.0,0.0,0.0,0.0
26,0.0,0.0,0.0,0.0
27,0.0,0.0,0.0,0.0
28,0.0,0.0,0.0,0.0
29,0.0,0.0,0.0,0.0
30,0.0,0.0,0.0,0.0
31,0.0,0.0,0.0,0.0
32,0.0,0.0,0.0,0.0
33,0.0,0.0,0.0,0.0
34,0.0,0.0,0.0,0.0
35,0.0,0.0,0.0,0.0
36,0.0,0.0,0.0,0.0
37,0.0,0.0,0.0,0.0
38,0.0,0.0,0.0,0.0
39,0.0,0.0,0.0,0.0
40,0.0,0.0,0.0,0.0
41,0.0,0.0,0.0,0.0
42,0.0,0.0,0.0,0.0
43,0.0,0.0,0.0,0.0
44,0.0,0.0,0.0,0.0
45,0.0,0.0,0.0,0.0
46,0.0,0.0,0.0,0.0
47,0.0,0.0,0.0,0.0
48,0.0,0.0,0.0,0.0
49,0.0,0.0,0.0,0.0
50,0.0,0.0,0.0,0.0
51,0.0,0.0,0.0,0.0
52,0.0,0.0,0.0,0.0
53,0.0,0.0,0.0,0.0
54,0.0,0.0,0.0,0.0
55,0.0,0.0,0.0,0.0
56,0.0,0.0,0.0,0.0
57,0.0,0.0,0.0,0.0
58,0.0,0.0,0.0,0.0
59,0.0,0.0,0.0,0.0
60,0.0,0.0,0.0,0.0
61,0.0,0.0,0.0,0.0
62,0.0,0.0,0.0,0.0
63,0.0,0.0,0.0,0.0
64,0.0,0.0,0.0,0.0
65,0.0,0.0,0.0,0.0
66,0.0,0.0,0.0,0.0
67,0.0,0.0,0.0,0.0
68,0.0,0.0,0.0,0.0
69,0.0,0.0,0.0,0.0
70,0.0,0.0,0.0,0.0
71,0.0,0.0,0.0,0.0
72,0.0,0.0,0.0,0.0
73,0.0,0.0,0.0,0.0
74,0.0,0.0,0.0,0.0
75,0.0,0.0,0.0,0.0
76,0.0,0.0,0.0,0.0
77,0.0,0.0,0.0,0.0
78,0.0,0.0,0.0,0.0
79,0.0,0.0,0.0,0.0
80,0.0,0.0,0.0,0.0
81,0.0,0.0,0.0,0.0
82,0.0,0.0,0.0,0.0
83,0.0,0.0,0.0,0.0
84,0.0,0.0,0.0,0.0
85,0.0,0.0,0.0,0.0
86,0.0,0.0,0.0,0.0
87,0.0,0.0,0.0,0.0
88,0.0,0.0,0.0,0.0
89,0.0,0.0,0.0,0.0
90,0.0,0.0,0.0,0.0
91,0.0,0.0,0.0,0.0
92,0.0,0.0,0.0,0.0
93,0.0,0.0,0.0,0.0
94,0.0,0.0,0.0,0.0
95,0.0,0.0,0.0,0.0
96,0.0,0.0,0.0,0.0
97,0.0,0.0,0.0,0.0
98,0.0,0.0,0.0,0.0
99,0.0,0.0,0.0,0.0
epoch,training loss,train accuracy,test loss,test accuracy
0,3.3647363736079288,0.6003010272979736,5.295066833496094,0.6142857074737549
1,3.0687880913416543,0.6082225441932678,5.055171012878418,0.6199405193328857
2,2.8109433559271007,0.621833086013794,4.626142978668213,0.625
3,2.6064442915794177,0.6179301738739014,4.829921722412109,0.5776786208152771
4,2.4671710026569857,0.6278693079948425,4.3743438720703125,0.6392857432365417
5,2.3250333269437156,0.636898934841156,4.809265613555908,0.6342262029647827
6,2.2260540357002845,0.6391149759292603,4.390534400939941,0.665773868560791
7,1.8776808014282813,0.6464245915412903,3.625150203704834,0.6535714864730835
8,1.6334972702539885,0.6534531116485596,3.4927163124084473,0.6267857551574707
9,1.4271606161044195,0.6523616313934326,2.3663201332092285,0.6577381491661072
10,1.311584738584665,0.6644506454467773,2.7425336837768555,0.677976131439209
11,1.1718633358295147,0.6728518009185791,1.5301485061645508,0.6886905431747437
12,1.6204605255371485,0.6493352651596069,1.5954020023345947,0.6729166507720947
13,1.0539795282559516,0.6786234378814697,2.06162166595459,0.6827380657196045
14,0.8504105462477758,0.698849081993103,1.0732320547103882,0.7086309790611267
15,0.8059966969184387,0.694516122341156,1.664919137954712,0.6967262029647827
16,0.7947481320454524,0.691307783126831,2.9243297576904297,0.6961309313774109
17,0.5633784654812936,0.7170735597610474,2.0751330852508545,0.7062500715255737
18,0.42119975311633867,0.7374148368835449,1.3836747407913208,0.7110118865966797
19,0.36851714169367766,0.7419130802154541,0.8529335260391235,0.7366071939468384
20,0.29147494794466555,0.7543163299560547,0.8846713304519653,0.7360119223594666
21,0.25830957752007705,0.7596745491027832,0.9387496113777161,0.7383928298950195
22,0.19664821735559365,0.7768241763114929,0.4650004506111145,0.7526785731315613
23,0.17094956644070455,0.785258412361145,0.813171923160553,0.7598214149475098
24,0.1672146499921114,0.7913773059844971,0.7478820085525513,0.7580356597900391
25,0.1398190120473886,0.7940067648887634,1.0678558349609375,0.776488184928894
26,0.11491666428553753,0.8084441423416138,0.6678931713104248,0.7726191282272339
27,0.10330698046928798,0.8165144920349121,0.8233954906463623,0.7711309790611267
28,0.0999502155643243,0.8162003755569458,0.48709583282470703,0.790773868560791
29,0.11371829035954598,0.8205828666687012,0.7034062743186951,0.7925595641136169
30,0.09975197061132161,0.8223854303359985,0.739905059337616,0.7872023582458496
31,0.09367426007221906,0.8293312788009644,0.7106137275695801,0.8044643402099609
32,0.06968034947147736,0.8399484157562256,0.6107138395309448,0.7997024059295654
33,0.0638778183895808,0.848944902420044,0.6031816005706787,0.8065476417541504
34,0.06773452050028703,0.8426936864852905,0.5331497192382812,0.8062500357627869
35,0.10078957141974033,0.8418006300926208,0.6942073106765747,0.7931548357009888
36,0.11659493192266195,0.8291493654251099,0.3339986205101013,0.8071429133415222
37,0.08917777861158054,0.8361613154411316,0.9181604981422424,0.8077380657196045
38,0.11237320877038516,0.8372527956962585,0.5100369453430176,0.8095237612724304
39,0.07393960807567988,0.8448270559310913,0.46347880363464355,0.8139880895614624
40,0.051040732994293556,0.863349199295044,0.4187895655632019,0.8279762268066406
41,0.05032896732863707,0.8698816299438477,0.913282036781311,0.8267857432365417
42,0.04603552655913891,0.8757524490356445,0.48640626668930054,0.829464316368103
43,0.03791443635828984,0.8841370940208435,0.4961922764778137,0.8404762148857117
44,0.03851062011642334,0.8860388994216919,0.5658208131790161,0.8345238566398621
45,0.03496745692040676,0.890322208404541,0.6666772961616516,0.8395833373069763
46,0.03311072977689596,0.8984090685844421,0.5353736877441406,0.836309552192688
47,0.12222190726643954,0.8449262976646423,0.7050803899765015,0.7895833849906921
48,0.21278854726980895,0.8053185343742371,0.4358806610107422,0.7714285850524902
49,0.16763209303220114,0.8096680045127869,1.3932325839996338,0.7824405431747437
50,0.14187586020964843,0.8111066818237305,0.4913294315338135,0.7961310148239136
51,0.08296695065039855,0.8416187763214111,0.7673075199127197,0.8184523582458496
52,0.062473197013903886,0.8588179349899292,0.7253490090370178,0.8223214149475098
53,0.053402483893128544,0.8696500658988953,0.4957869052886963,0.8419643640518188
54,0.043089804072410635,0.8830952644348145,0.433157742023468,0.8497023582458496
55,0.03241720881599646,0.8962923288345337,0.5180221796035767,0.8553571701049805
56,0.02601916139993148,0.9077363014221191,0.47309327125549316,0.8625000715255737
57,0.022569442621599406,0.9170966148376465,0.5580196976661682,0.8619047999382019
58,0.019323469903797675,0.9257789850234985,0.4719215929508209,0.8666666746139526
59,0.017305566571079768,0.9306244850158691,0.3502609133720398,0.8616071939468384
60,0.01760420659318184,0.9295330047607422,0.46332526206970215,0.8693451881408691
61,0.016079199452621814,0.9349408149719238,0.5145538449287415,0.8660714626312256
62,0.015232948371424125,0.9382814764976501,0.3737761974334717,0.868154764175415
63,0.016131966947936095,0.9375869035720825,0.434265673160553,0.867559552192688
64,0.016988028915455707,0.9377192258834839,0.538585901260376,0.8711309432983398
65,0.022170430168700524,0.932327926158905,0.38514918088912964,0.8711309432983398
66,0.02311129719974139,0.9298803210258484,0.6557227373123169,0.867559552192688
67,0.020754435481742408,0.929069995880127,0.3390823304653168,0.870238184928894
68,0.029703785593693074,0.9199246764183044,0.41311416029930115,0.8428571224212646
69,0.03268230018707422,0.9158729314804077,0.42822474241256714,0.8550595641136169
70,0.028213695503580265,0.9154428839683533,0.42887747287750244,0.8598214387893677
71,0.039620270379460774,0.9090924263000488,0.5641710758209229,0.841369092464447
72,0.058146526893744103,0.8861546516418457,0.6183267831802368,0.8026785850524902
73,0.10107721522068366,0.8466296195983887,0.37162572145462036,0.819345235824585
74,0.11562796567495053,0.8278263807296753,0.6042794585227966,0.7773809432983398
75,0.13966767661846602,0.8176887035369873,0.6690077781677246,0.7904762029647827
76,0.10561302170539513,0.83235764503479,1.023338794708252,0.8357143402099609
77,0.08668070869185986,0.8544023036956787,0.5167598128318787,0.821428656578064
78,0.054076201401841946,0.8748099207878113,0.41198834776878357,0.8517857789993286
79,0.030348770654736422,0.9040319323539734,0.3967447876930237,0.8732142448425293
80,0.021815707811560385,0.919015109539032,0.4449596703052521,0.8741071224212646
81,0.016751700701812904,0.9351558089256287,0.4329127073287964,0.8767857551574707
82,0.015054244667482682,0.94167160987854,0.45448166131973267,0.8785714507102966
83,0.016327184195128772,0.9394060373306274,0.3605400323867798,0.8800595998764038
84,0.013449123738190303,0.9482536315917969,0.43138667941093445,0.8809523582458496
85,0.010970269544766499,0.9572831988334656,0.3253214359283447,0.8880952596664429
86,0.013007023395636143,0.9532315135002136,0.31857097148895264,0.883928656578064
87,0.01768669944543105,0.9431104063987732,0.3639599680900574,0.8776785731315613
88,0.01745343091300665,0.9409770965576172,0.5294943451881409,0.8854166865348816
89,0.014078773259638976,0.9500893354415894,0.5179635286331177,0.8782738447189331
90,0.013111973348527383,0.9500727653503418,0.25725284218788147,0.8895833492279053
91,0.013038151825849827,0.9546041488647461,0.4674815237522125,0.8883929252624512
92,0.011189942642186698,0.9618972539901733,0.470034122467041,0.881845235824585
93,0.012410123080301743,0.9568036794662476,0.3589089512825012,0.8869047164916992
94,0.012327402471922912,0.9572170972824097,0.45452696084976196,0.8877977132797241
95,0.012533441627732454,0.9604584574699402,0.3295539915561676,0.8904761672019958
96,0.011331183776163902,0.9603592753410339,0.2977988123893738,0.8872023820877075
97,0.011057538529619193,0.9625090956687927,0.37219536304473877,0.8880952596664429
98,0.018022529159982998,0.947096049785614,0.32531529664993286,0.8785714507102966
99,0.045711868323194675,0.9094562530517578,0.6162751913070679,0.8568452596664429
epoch,training loss,train accuracy,test loss,test accuracy
0,3.1895267993975907,0.6141430735588074,5.2078857421875,0.6199405193328857
1,2.940020371706058,0.6071145534515381,4.904685020446777,0.6229166984558105
2,2.731067969248845,0.6139280796051025,4.63780403137207,0.6363095045089722
3,2.581684259267954,0.6319706439971924,4.555143356323242,0.6214286088943481
4,2.449359893798828,0.6342529058456421,5.186314582824707,0.6514881253242493
5,2.2331644556461234,0.6448700428009033,3.8152034282684326,0.6458333730697632
6,2.2637735972037683,0.6425382494926453,4.3828020095825195,0.6604166626930237
7,2.3220687126502013,0.6398094892501831,4.728870391845703,0.6622024178504944
8,1.9922023018201191,0.6466560959815979,3.051107406616211,0.6479166746139526
9,1.5836245616277058,0.6604650616645813,3.337106227874756,0.6767858266830444
10,1.6764420790550036,0.6619865298271179,3.532168388366699,0.6645833253860474
11,1.2114922954485967,0.6678242683410645,2.635277509689331,0.6842262148857117
12,0.942887932062149,0.6879507303237915,1.4756395816802979,0.673214316368103
13,0.7047658012463496,0.701263427734375,0.8481311202049255,0.6955356597900391
14,0.6638644903134077,0.7078124284744263,0.7541697025299072,0.71875
15,0.5737854540348053,0.7133525609970093,0.6418591737747192,0.7148809432983398
16,0.5601159364749224,0.7195210456848145,1.1449167728424072,0.7229167222976685
17,0.5219445152160449,0.7198848724365234,0.875648021697998,0.7095238566398621
18,0.374406119569754,0.7358934283256531,0.5439883470535278,0.742559552192688
19,0.33315862982701033,0.7468578815460205,0.7290295958518982,0.7303571701049805
20,0.3094786138106615,0.7509427070617676,0.4064604640007019,0.7505952715873718
21,0.2566202745223657,0.7651816606521606,0.4717516303062439,0.7610119581222534
22,0.1875024669063397,0.7813886404037476,0.49721068143844604,0.7675595283508301
23,0.16672612440127593,0.7931467890739441,0.35904255509376526,0.7729166746139526
24,0.14004538895992133,0.8002249598503113,0.45592427253723145,0.7791666984558105
25,0.12362017138646199,0.8083285093307495,0.418973833322525,0.785714328289032
26,0.12090511171099468,0.8132896423339844,0.4129474461078644,0.7797619104385376
27,0.10502693668389931,0.8191605806350708,0.30060306191444397,0.7955357432365417
28,0.09089422608033204,0.8290831446647644,0.36877864599227905,0.8062500357627869
29,0.0775476414232682,0.8365912437438965,0.33522704243659973,0.805654764175415
30,0.07291587327535336,0.8417178988456726,0.34826233983039856,0.8130952715873718
31,0.0685794856876899,0.849705696105957,0.29598185420036316,0.807440459728241
32,0.06918014175234696,0.8501521944999695,0.3338596820831299,0.8125
33,0.07820100824420269,0.8412052989006042,0.2315015345811844,0.8023809790611267
34,0.06655634404757084,0.8515082597732544,0.44479280710220337,0.8235119581222534
35,0.06474726169537275,0.8530628085136414,0.23863372206687927,0.8184523582458496
36,0.0652794500765128,0.8557915091514587,0.3013905882835388,0.8139880895614624
37,0.06019089113061245,0.8603559732437134,0.33817389607429504,0.8199405074119568
38,0.062254476241576366,0.8612985610961914,0.2358042299747467,0.8184523582458496
39,0.1407879817371185,0.8288020491600037,0.6032248735427856,0.8050596117973328
40,0.1809792113609803,0.8031851649284363,0.3719636797904968,0.7869048118591309
41,0.1540973853224363,0.8069061636924744,0.4330974221229553,0.7916666865348816
42,0.1218417342274617,0.824386477470398,0.5250914096832275,0.8148810267448425
43,0.0892996554955458,0.844314455986023,0.23309367895126343,0.8199405074119568
44,0.06625788735273556,0.8560561537742615,0.364412784576416,0.8244048357009888
45,0.058555981574150234,0.8663260340690613,0.28427162766456604,0.8205356597900391
46,0.05692115827248646,0.8671528697013855,0.3369763493537903,0.829464316368103
47,0.046012935013725206,0.8786630630493164,0.22564347088336945,0.8422619700431824
48,0.03881151291231314,0.8848151564598083,0.29583925008773804,0.843154788017273
49,0.030634176654693406,0.8974664211273193,0.24569466710090637,0.843154788017273
50,0.025052752059239607,0.9070913791656494,0.2575240135192871,0.8571428656578064
51,0.021066671500030238,0.9166666865348816,0.2370881736278534,0.848214328289032
52,0.019204561001597308,0.9225706458091736,0.23322682082653046,0.8625000715255737
53,0.018156402696592685,0.9267050623893738,0.24558104574680328,0.8538690805435181
54,0.019578840607442916,0.9252166748046875,0.29057157039642334,0.860714316368103
55,0.018981786516423408,0.9251836538314819,0.25458720326423645,0.8592262268066406
56,0.01779442559927702,0.9290368556976318,0.31561458110809326,0.8598214387893677
57,0.021289609181575287,0.9212641716003418,0.2688474953174591,0.8502976298332214
58,0.025299437391834382,0.9150956869125366,0.3026217818260193,0.8568452596664429
59,0.038858470387565784,0.9004597663879395,0.22296367585659027,0.8449405431747437
60,0.04411570608424835,0.8925051689147949,0.24492713809013367,0.8440476655960083
61,0.048549502180554927,0.8846993446350098,0.264498770236969,0.838988184928894
62,0.04644679750960607,0.8816730380058289,0.33916500210762024,0.8348214030265808
63,0.0446758239219586,0.8883211016654968,0.28907328844070435,0.8464285731315613
64,0.03526003376986736,0.8999637365341187,0.1851300448179245,0.8458333015441895
65,0.033454082954006314,0.9034366011619568,0.3038702607154846,0.8616071939468384
66,0.043783436266657635,0.8990375399589539,0.22003337740898132,0.8500000834465027
67,0.07630800025967452,0.8726764917373657,0.447748064994812,0.8241071701049805
68,0.0776360117090054,0.8587021827697754,0.24390138685703278,0.8377976417541504
69,0.11906498708786109,0.8483495712280273,0.34993138909339905,0.8104166984558105
70,0.12484098569704936,0.8239234685897827,0.49271321296691895,0.8270833492279053
71,0.11655836342236935,0.8367235660552979,0.3585813045501709,0.8181547522544861
72,0.07939230707975534,0.8552788496017456,0.21656636893749237,0.8312500715255737
73,0.04797787735095391,0.8806642293930054,0.36975836753845215,0.848214328289032
74,0.041482873260974884,0.8911986351013184,0.24775803089141846,0.8455357551574707
75,0.03287391460094696,0.9007740020751953,0.19968809187412262,0.8690476417541504
76,0.027088582324676026,0.9105477333068848,0.2560449242591858,0.8571428656578064
77,0.02066219602830899,0.924456000328064,0.2868052124977112,0.874404788017273
78,0.018765820763432063,0.9332374334335327,0.27225056290626526,0.8708333969116211
79,0.01485127069724676,0.9408778548240662,0.1874387264251709,0.8732142448425293
80,0.012662392109632492,0.9467487335205078,0.2959045469760895,0.8717262148857117
81,0.0128741682244417,0.9483858942985535,0.22836554050445557,0.8779762983322144
82,0.012518540621759036,0.9491301774978638,0.2568858861923218,0.8761905431747437
83,0.011175003869888874,0.9555301666259766,0.23366592824459076,0.8782738447189331
84,0.011129221974466091,0.9553979635238647,0.20638194680213928,0.8800595998764038
85,0.010886753694369243,0.9584243297576904,0.2264089584350586,0.8809524774551392
86,0.01131433917161746,0.9583085775375366,0.2233305722475052,0.8821429014205933
87,0.013577203206622448,0.9502216577529907,0.2525220513343811,0.8741071224212646
88,0.015054837502061557,0.9482702016830444,0.32562902569770813,0.8747023940086365
89,0.017857850768054143,0.9398691058158875,0.24809443950653076,0.879464328289032
90,0.020278218464973647,0.9383972883224487,0.3050822913646698,0.8720238208770752
91,0.025103033926242437,0.9262585639953613,0.3771396279335022,0.8782738447189331
92,0.03466465367147556,0.9167493581771851,0.25305426120758057,0.8479167222976685
93,0.04520726394958985,0.8925713300704956,0.4736463725566864,0.8601190447807312
94,0.03943777261063074,0.9050407409667969,0.3212617039680481,0.8610119223594666
95,0.033508626505350456,0.9108785390853882,0.33312761783599854,0.8517857789993286
96,0.03564344389507404,0.912284255027771,0.3274870812892914,0.867559552192688
97,0.038971712144139484,0.9055368304252625,0.3840886950492859,0.8651785850524902
98,0.04218185826753958,0.9025766253471375,0.22769029438495636,0.8645833730697632
99,0.04224254907323764,0.8979625701904297,0.5028596520423889,0.8383929133415222
epoch,training loss,train accuracy,test loss,test accuracy
0,3.2043388990255504,0.6098763346672058,4.98553466796875,0.5997024178504944
1,2.9593790066547885,0.6174505949020386,4.6833343505859375,0.6550595760345459
2,2.951232294241587,0.6228914856910706,4.671029567718506,0.6041666865348816
3,2.677360088397295,0.6254217624664307,4.846861362457275,0.6473214626312256
4,2.4895002261186256,0.6296884417533875,4.129944324493408,0.6437500715255737
5,2.1665055874066477,0.6401402950286865,3.4736227989196777,0.6511905193328857
6,2.0067478785148034,0.6394787430763245,3.160203456878662,0.6517857313156128
7,2.15644533206255,0.6401898264884949,3.245812177658081,0.6550595760345459
8,1.5751232550694392,0.6580836772918701,3.1834797859191895,0.6613095998764038
9,1.4416655882810936,0.6634749174118042,1.7666139602661133,0.665773868560791
10,1.2790988041804388,0.6692631244659424,2.164851427078247,0.6449404954910278
11,1.16500863356468,0.673182487487793,1.4049148559570312,0.6782738566398621
12,0.7914810578028361,0.6942349672317505,1.635633111000061,0.6955357789993286
13,0.6635910341372857,0.7069028615951538,1.0640543699264526,0.6934523582458496
14,0.5788150735390492,0.7200173139572144,1.1449111700057983,0.7089285850524902
15,0.4921046289113852,0.7303697466850281,0.9234759211540222,0.7282738089561462
16,0.42397784422605467,0.7407058477401733,0.6966098546981812,0.7375000715255737
17,0.3870750990433571,0.7481478452682495,0.7538686394691467,0.7383929491043091
18,0.32895669952417034,0.7631640434265137,0.8208082914352417,0.7336310148239136
19,0.29119127950607204,0.772524356842041,0.5162365436553955,0.7476190328598022
20,0.26282984495927125,0.7804128527641296,0.46515828371047974,0.7592262029647827
21,0.23064923592102834,0.782314658164978,0.7358003258705139,0.7517857551574707
22,0.38096409501173556,0.7483958601951599,0.824897825717926,0.7336310148239136
23,0.31351178196760326,0.7578058242797852,0.6992636919021606,0.759523868560791
24,0.20080373398004434,0.7742608785629272,0.46078914403915405,0.776488184928894
25,0.17635955871679845,0.7821658849716187,1.141623854637146,0.7732143402099609
26,0.1713903756477894,0.7893266081809998,0.6014361381530762,0.7809523940086365
27,0.1375573571675863,0.8006383776664734,0.3765815198421478,0.7794643640518188
28,0.11656373710586475,0.815985381603241,0.3654201626777649,0.7916666865348816
29,0.08285309498508771,0.8277932405471802,0.42473217844963074,0.8002976179122925
30,0.07108225090763508,0.840742290019989,0.3121644854545593,0.8139881491661072
31,0.06507611265167212,0.8462657928466797,0.4659613370895386,0.8154762983322144
32,0.05986487086957846,0.8509790301322937,0.34493666887283325,0.8139880895614624
33,0.05296076719577496,0.8576107025146484,0.3553704619407654,0.8193453550338745
34,0.047941541203703635,0.8648046255111694,0.314552903175354,0.8187500238418579
35,0.04255485525115942,0.87535560131073,0.3969948887825012,0.8247024416923523
36,0.03716903132123825,0.8809453248977661,0.36130931973457336,0.8315476179122925
37,0.037532411133631684,0.8817722201347351,0.39199298620224,0.8300595283508301
38,0.034198578303823106,0.8865516185760498,0.36455321311950684,0.8351191282272339
